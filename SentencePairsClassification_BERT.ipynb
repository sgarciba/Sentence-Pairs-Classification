{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERTbase Sentence Pairs Classification - SNLI.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e3f0b23bbe2c4befa06ccc0aefce2a2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_bc89459ac3054987becf3b928cae049d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_7f2d7761ec744754915915a4f2cf3779",
              "IPY_MODEL_ddebbff5f1484380954771c6ef2e74ac"
            ]
          }
        },
        "bc89459ac3054987becf3b928cae049d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7f2d7761ec744754915915a4f2cf3779": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e4c668575a424a95926de7d648949faf",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b87c18159abc4840a58f6e9f35a31044"
          }
        },
        "ddebbff5f1484380954771c6ef2e74ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b478f738011a4700b5e47df30ed356e3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 2.20MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c843fe61c5344e48a7d5f2b2b2c809a0"
          }
        },
        "e4c668575a424a95926de7d648949faf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b87c18159abc4840a58f6e9f35a31044": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b478f738011a4700b5e47df30ed356e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c843fe61c5344e48a7d5f2b2b2c809a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a707397ffd6c4b5a8ed81f93d6ae1d38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_27d86e5b6ac44edc801c1b565bc80c1f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f2bd052f21734567ad721b403252df9e",
              "IPY_MODEL_ecdef0490d3940458192e5707aaea48c"
            ]
          }
        },
        "27d86e5b6ac44edc801c1b565bc80c1f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f2bd052f21734567ad721b403252df9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_3729317bc3074a2086a8f614f2533210",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bb7d38cefa97441c8c6306badc862640"
          }
        },
        "ecdef0490d3940458192e5707aaea48c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_846f13a855a546e1852d3ea376b08701",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [00:10&lt;00:00, 41.5B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c5e4f119802a4c21943b3b7f2edd0bf5"
          }
        },
        "3729317bc3074a2086a8f614f2533210": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bb7d38cefa97441c8c6306badc862640": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "846f13a855a546e1852d3ea376b08701": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c5e4f119802a4c21943b3b7f2edd0bf5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b743741fd83c4c06811f9942cf2075f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_6493158482f044c0a9730ddd1f826290",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9e3efc11cfb5479c932033daedf15047",
              "IPY_MODEL_56e5d255bdbf459e86818a854cd01877"
            ]
          }
        },
        "6493158482f044c0a9730ddd1f826290": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9e3efc11cfb5479c932033daedf15047": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_7e384158b01c46f1bd71916f40d500c8",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_43e1d470c04a4f828c18e393435e500b"
          }
        },
        "56e5d255bdbf459e86818a854cd01877": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d09ad4b8ff4e4ff0ba2f040b6006ac06",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [00:09&lt;00:00, 44.7MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f0bdcafaa941474abd5d9073e96622c2"
          }
        },
        "7e384158b01c46f1bd71916f40d500c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "43e1d470c04a4f828c18e393435e500b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d09ad4b8ff4e4ff0ba2f040b6006ac06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f0bdcafaa941474abd5d9073e96622c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9s9C0gPVVw3L",
        "colab_type": "text"
      },
      "source": [
        "#__BERT SENTENCE PAIRS CLASSIFICATION - SNLI DATASET__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uPTuXjvfWAfi",
        "colab_type": "text"
      },
      "source": [
        " In this notebook we will be implementing BERT for a multi-classification problem. The dataset used for this experiment is the SNLI, which has two pair sentences and a label for every pair. \n",
        "\n",
        " BERT is a recently new neural network architecture that is capable to extract most of the meaning of a given text and it has been applied to multiple tasks in NLU, including sequence classification.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "phuXddD31eDw",
        "colab_type": "text"
      },
      "source": [
        "### 1. SET UP"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z9m9lAym1vxC",
        "colab_type": "text"
      },
      "source": [
        "This model performs lots of operations and it requires to make use of a GPU in order to accelerate the computation time. We also need to download some packages such as the transformers and wget, this way we can use the interface of pytorch to apply BERT and download the data from internet."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M2yHBdvVVfHJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7b90f07f-e87d-4b95-dcae-a80937c6010a"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Get the GPU device name\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "# The device name should look like the following:\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    raise SystemError('GPU not available')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4vE_HUw2k6b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "5ad85034-1d46-461b-edc1-d7b2317a1b25"
      },
      "source": [
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU   \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are {} GPU(s) available.'.format(torch.cuda.device_count()))\n",
        "\n",
        "    print('GPU name:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not, use the CPU\n",
        "else:\n",
        "    print('GPU not found, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "GPU name: Tesla K80\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XWMxiX8524N8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 615
        },
        "outputId": "1c48056a-0748-4aaf-d9d6-7d0a02b6dc07"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/3c/91ed8f5c4e7ef3227b4119200fc0ed4b4fd965b1f0172021c25701087825/transformers-3.0.2-py3-none-any.whl (769kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 778kB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Collecting sentencepiece!=0.1.92\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.1MB 16.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Collecting tokenizers==0.8.1.rc1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/d0/30d5f8d221a0ed981a186c8eb986ce1c94e3a6e87f994eae9f4aa5250217/tokenizers-0.8.1rc1-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.0MB 21.1MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 890kB 24.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=3c0a2f40b6ca7e0b3c61e9d0f439a82dd6248b3c49d2b437e82edf848ff17d0e\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sentencepiece, tokenizers, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.8.1rc1 transformers-3.0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1GvON0hl4BuB",
        "colab_type": "text"
      },
      "source": [
        "### 2. DATA EXPLORATION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_SaCC5r4F8c",
        "colab_type": "text"
      },
      "source": [
        "The SNLI dataset has three main columns {sentence1, sentence2 and gold_label}. For every pair of sentences we have a label whether they are an entailment, neutral or a contradiction to one another. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3S29tMsyvqrZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "5980a944-e11b-40b9-986d-dfc90923196e"
      },
      "source": [
        "# Download the data from the internet\n",
        "!wget -P /content/project_data/ -c  \"https://nlp.stanford.edu/projects/snli/snli_1.0.zip\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-08-25 08:40:37--  https://nlp.stanford.edu/projects/snli/snli_1.0.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 94550081 (90M) [application/zip]\n",
            "Saving to: â€˜/content/project_data/snli_1.0.zipâ€™\n",
            "\n",
            "snli_1.0.zip        100%[===================>]  90.17M  4.42MB/s    in 29s     \n",
            "\n",
            "2020-08-25 08:41:06 (3.14 MB/s) - â€˜/content/project_data/snli_1.0.zipâ€™ saved [94550081/94550081]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2TW6pede36k_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "fbff32c2-e1dc-4834-902e-533e1700e90d"
      },
      "source": [
        "\n",
        "# Unzip the dataset\n",
        "!unzip '/content/project_data/snli_1.0.zip'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/project_data/snli_1.0.zip\n",
            "   creating: snli_1.0/\n",
            "  inflating: snli_1.0/.DS_Store      \n",
            "   creating: __MACOSX/\n",
            "   creating: __MACOSX/snli_1.0/\n",
            "  inflating: __MACOSX/snli_1.0/._.DS_Store  \n",
            " extracting: snli_1.0/Icon           \n",
            "  inflating: __MACOSX/snli_1.0/._Icon  \n",
            "  inflating: snli_1.0/README.txt     \n",
            "  inflating: __MACOSX/snli_1.0/._README.txt  \n",
            "  inflating: snli_1.0/snli_1.0_dev.jsonl  \n",
            "  inflating: snli_1.0/snli_1.0_dev.txt  \n",
            "  inflating: snli_1.0/snli_1.0_test.jsonl  \n",
            "  inflating: snli_1.0/snli_1.0_test.txt  \n",
            "  inflating: snli_1.0/snli_1.0_train.jsonl  \n",
            "  inflating: snli_1.0/snli_1.0_train.txt  \n",
            "  inflating: __MACOSX/._snli_1.0     \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24BUGh7P5LaX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "e8e1edfd-2488-4d39-95d2-79ac9056247b"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Create a pandas dataframe\n",
        "train_df = pd.read_csv(\"./snli_1.0/snli_1.0_train.txt\", delimiter='\\t')\n",
        "train_df = train_df[['sentence1', 'sentence2', 'gold_label']]\n",
        "\n",
        "# Remove all the rows labeled as '-' and NaN\n",
        "train_df = train_df.loc[train_df['gold_label'] != '-']\n",
        "train_df = train_df.dropna()\n",
        "\n",
        "# Create a subset of the data\n",
        "train_df = train_df.iloc[:12500,:]\n",
        "\n",
        "# Check the length of the training set\n",
        "print('Length of the training set:', len(train_df))\n",
        "\n",
        "# Display the top 5 rows\n",
        "train_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of the training set: 12500\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence1</th>\n",
              "      <th>sentence2</th>\n",
              "      <th>gold_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A person on a horse jumps over a broken down a...</td>\n",
              "      <td>A person is training his horse for a competition.</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A person on a horse jumps over a broken down a...</td>\n",
              "      <td>A person is at a diner, ordering an omelette.</td>\n",
              "      <td>contradiction</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A person on a horse jumps over a broken down a...</td>\n",
              "      <td>A person is outdoors, on a horse.</td>\n",
              "      <td>entailment</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Children smiling and waving at camera</td>\n",
              "      <td>They are smiling at their parents</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Children smiling and waving at camera</td>\n",
              "      <td>There are children present</td>\n",
              "      <td>entailment</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           sentence1  ...     gold_label\n",
              "0  A person on a horse jumps over a broken down a...  ...        neutral\n",
              "1  A person on a horse jumps over a broken down a...  ...  contradiction\n",
              "2  A person on a horse jumps over a broken down a...  ...     entailment\n",
              "3              Children smiling and waving at camera  ...        neutral\n",
              "4              Children smiling and waving at camera  ...     entailment\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YkI-v_bi6s4t",
        "colab_type": "text"
      },
      "source": [
        "BERT needs a certain input string, where two sentences have to be separated by the [SEP] character. It is the only way that the model understands that is processing a sequence of sentences (A and B)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QUWq_Q9idpkZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get the vector of sentences and labels\n",
        "import numpy as np\n",
        "\n",
        "sentA = train_df.sentence1.values\n",
        "sentB = train_df.sentence2.values\n",
        "\n",
        "# Transform string labels into int labels\n",
        "int_label = {'entailment':0, 'neutral':1, 'contradiction':2}\n",
        "\n",
        "labels = np.array([int_label[i] for i in train_df.gold_label])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ILCk_WeW9nrr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "530e0cc1-d39e-4f4e-845d-9c364df7c82c"
      },
      "source": [
        "# Shape of the sentences and labels\n",
        "print('Shape sentences A:', sentA.shape)\n",
        "print('Shape sentences B:', sentB.shape)\n",
        "print('Shape labels:', labels.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape sentences A: (12500,)\n",
            "Shape sentences B: (12500,)\n",
            "Shape labels: (12500,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pkwE1HT__fQC",
        "colab_type": "text"
      },
      "source": [
        "### 3. INPUT REPRESENTATION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fp6ckbuD_r3U",
        "colab_type": "text"
      },
      "source": [
        "### 3.1 Input IDS and Sentence IDS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CeXoZJCW9pD1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83,
          "referenced_widgets": [
            "e3f0b23bbe2c4befa06ccc0aefce2a2e",
            "bc89459ac3054987becf3b928cae049d",
            "7f2d7761ec744754915915a4f2cf3779",
            "ddebbff5f1484380954771c6ef2e74ac",
            "e4c668575a424a95926de7d648949faf",
            "b87c18159abc4840a58f6e9f35a31044",
            "b478f738011a4700b5e47df30ed356e3",
            "c843fe61c5344e48a7d5f2b2b2c809a0"
          ]
        },
        "outputId": "dd02c8c8-ab0e-4cf3-8f4d-433d40cf24fe"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# Load the BERT tokenizer. We will be using the base model of BERT (12 layers)\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading BERT tokenizer...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e3f0b23bbe2c4befa06ccc0aefce2a2e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descriptiâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9GlLlKRlA0Rr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "f7f9f3c4-1cad-43be-87e1-00c738f4fec5"
      },
      "source": [
        "# Tokenize all the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "sent_ids = []\n",
        "\n",
        "for i in range(0,12500):\n",
        "    # 'encode' will tokenize every word in the sentence, \n",
        "    # Add [CLS] and [SEP] special characters to the beggining and end of the sentence (also add [SEP] between sentA and B)\n",
        "    # Finally map every token to their ID\n",
        "    encoded_sent = tokenizer(\n",
        "                        sentA[i],\n",
        "                        sentB[i],                   \n",
        "                        add_special_tokens = True)\n",
        "    \n",
        "    sent_ids.append(encoded_sent['token_type_ids'])\n",
        "    input_ids.append(encoded_sent['input_ids'])\n",
        "\n",
        "# Example of the first sentence\n",
        "print('Pair Sentence: {0} {1}'.format(sentA[0],sentB[0]))\n",
        "print('Sentence IDS:', sent_ids[0])\n",
        "print('BERT tokens IDs:', input_ids[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pair Sentence: A person on a horse jumps over a broken down airplane. A person is training his horse for a competition.\n",
            "Sentence IDS: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "BERT tokens IDs: [101, 1037, 2711, 2006, 1037, 3586, 14523, 2058, 1037, 3714, 2091, 13297, 1012, 102, 1037, 2711, 2003, 2731, 2010, 3586, 2005, 1037, 2971, 1012, 102]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QqRlXiqgDmrg",
        "colab_type": "text"
      },
      "source": [
        "### 3.2 Padding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jskBgHF7pPji",
        "colab_type": "text"
      },
      "source": [
        "Not all the sentences have the same length. To correct that, we use padding which is adding another special character [PAD] to the end of every sentences, so the length of every vector is the same. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J80Goa-IBx5Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8a4a8193-abcb-4694-b0cf-19a96319304f"
      },
      "source": [
        "# Find the largest sentence in our IDs vector\n",
        "print('Length of the longest sentence:', max([len(sent) for sent in input_ids]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of the longest sentence: 94\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-f-_PkWJC_5g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "920909c7-e396-4578-9ae0-d12c483c2ef7"
      },
      "source": [
        "# All the sentence inputs need to have the same length\n",
        "# That's why we use padding to put additional tokens [PAD] to those sentences that are shorter than the largest one \n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Set the maximum sequence length. It needs to be larger than 94\n",
        "max_len = 100\n",
        "\n",
        "print('Padding all the sentences to:',max_len)\n",
        "\n",
        "# Set PAD IDs as value=0 for the attention mask\n",
        "# \"post\" means that we add those special characters to the end of the sentence\n",
        "input_ids = pad_sequences(input_ids, maxlen=max_len, dtype=\"long\", \n",
        "                          value=0, truncating=\"post\", padding=\"post\")\n",
        "\n",
        "# SEt the PAD IDs as 1, as we move them to the back of the sentence\n",
        "sent_ids = pad_sequences(sent_ids, maxlen=max_len, dtype=\"long\", \n",
        "                          value=1, truncating=\"post\", padding=\"post\")\n",
        "\n",
        "print('Padding completed!')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Padding all the sentences to: 100\n",
            "Padding completed!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8y2JOprvGfnT",
        "colab_type": "text"
      },
      "source": [
        "### 3.3 Masked Language Modeling (MLM)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zEOnfroOr37p",
        "colab_type": "text"
      },
      "source": [
        "Part of the Pre-Training of BERT is MLM, that is replacing 15% of the tokens by a MASK character. The model will try to predict the right token by its context."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8TfxK7TzGJvd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create attention mask vector\n",
        "att_masks = []\n",
        "\n",
        "for sent in input_ids:\n",
        "   \n",
        "    # This vector will have two possible values [0,1]. All the padding tokens can't be masked, so we need to set them as 0, the rest as 1\n",
        "    mask = [int(id > 0) for id in sent]\n",
        "    att_masks.append(mask)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3TShjBmKIw4J",
        "colab_type": "text"
      },
      "source": [
        "### 3. SPLIT DATASET"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "705xIhWuIG5o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the data where 90% is for training and 10% for validation (development)\n",
        "X_train, X_dev, y_train, y_dev = train_test_split(input_ids, labels, \n",
        "                                                            random_state=203, test_size=0.1)\n",
        "# Same split for the masks vector\n",
        "masks_train, masks_dev, _, _ = train_test_split(att_masks, labels,\n",
        "                                             random_state=203, test_size=0.1)\n",
        "\n",
        "# Same split for the sent_ids vector\n",
        "sentID_train, sentID_dev, _, _ = train_test_split(sent_ids, labels,\n",
        "                                             random_state=203, test_size=0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b8rPC3gjIFFC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Transform the inputs, labels, attention masks and sentence IDs vectors into torch tensors\n",
        "X_train = torch.tensor(X_train)\n",
        "X_dev = torch.tensor(X_dev)\n",
        "\n",
        "y_train = torch.tensor(y_train)\n",
        "y_dev = torch.tensor(y_dev)\n",
        "\n",
        "masks_train = torch.tensor(masks_train)\n",
        "masks_dev = torch.tensor(masks_dev)\n",
        "\n",
        "sentID_train = torch.tensor(sentID_train)\n",
        "sentID_dev = torch.tensor(sentID_dev)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zYUNwmA7LpAj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# To save memory during our training process, we use the DataLoader class to create an iterator\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "batch_size = 32 # The optimum bacth sizes are 16 or 32\n",
        "\n",
        "# Create the DataLoader for our training set.\n",
        "train_data = TensorDataset(X_train, masks_train, sentID_train, y_train)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "# Create the DataLoader for our validation set.\n",
        "dev_data = TensorDataset(X_dev, masks_dev, sentID_dev, y_dev)\n",
        "dev_sampler = SequentialSampler(dev_data)\n",
        "dev_dataloader = DataLoader(dev_data, sampler=dev_sampler, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BTWp-1_7P5Vh",
        "colab_type": "text"
      },
      "source": [
        "### 4. DATA MODELING"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pgONNnHvP0bx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "a707397ffd6c4b5a8ed81f93d6ae1d38",
            "27d86e5b6ac44edc801c1b565bc80c1f",
            "f2bd052f21734567ad721b403252df9e",
            "ecdef0490d3940458192e5707aaea48c",
            "3729317bc3074a2086a8f614f2533210",
            "bb7d38cefa97441c8c6306badc862640",
            "846f13a855a546e1852d3ea376b08701",
            "c5e4f119802a4c21943b3b7f2edd0bf5",
            "b743741fd83c4c06811f9942cf2075f2",
            "6493158482f044c0a9730ddd1f826290",
            "9e3efc11cfb5479c932033daedf15047",
            "56e5d255bdbf459e86818a854cd01877",
            "7e384158b01c46f1bd71916f40d500c8",
            "43e1d470c04a4f828c18e393435e500b",
            "d09ad4b8ff4e4ff0ba2f040b6006ac06",
            "f0bdcafaa941474abd5d9073e96622c2"
          ]
        },
        "outputId": "2f251192-55c2-4df4-8447-75d70dd7c263"
      },
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "# Load the BertForSequenceClassification (model for fine-tuning)\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\", # Use BERTbase model (12 layers)\n",
        "    num_labels = 3, # Set the number of classes \n",
        "    output_attentions = False,\n",
        "    output_hidden_states = False)\n",
        "\n",
        "# Run this model on the GPU\n",
        "model.cuda()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a707397ffd6c4b5a8ed81f93d6ae1d38",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_â€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b743741fd83c4c06811f9942cf2075f2",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descriâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmnfHoAtTrEa",
        "colab_type": "text"
      },
      "source": [
        "### 4.1 Hiper-Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tw1xa8pkR85b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Adam optimizer\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, # learning rate (authors recommend: [5e-5, 3e-5, 2e-5])\n",
        "                  eps = 1e-8)\n",
        "\n",
        "# Number of training epochs (authors recommend between 2 and 4)\n",
        "epochs = 4\n",
        "\n",
        "# Total number of training steps is the number of batches * number of epochs\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0,\n",
        "                                            num_training_steps = total_steps)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ZGcjt2MUqyS",
        "colab_type": "text"
      },
      "source": [
        "### 4.2 Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eajGsCZAUh4k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yh0Vv3AoVAsX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "861c7602-2363-4a3e-c4fb-a3ead4e316a0"
      },
      "source": [
        "import random\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Set the same seed value to make it reproducible\n",
        "seed_val = 203\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# Store the average loss\n",
        "loss_values = []\n",
        "\n",
        "# Loop over the epochs\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ============= Training Phase =================\n",
        "    \n",
        "    print('\\n======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('> Training Mode...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for every epoch\n",
        "    total_loss = 0\n",
        "\n",
        "    # Let the know the model that is on training mode\n",
        "    model.train()\n",
        "\n",
        "    # For each batch in the train set\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Check the progress every 40 batches\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('\\tBatch {0}/{1}.\\tElapsed: {2}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Unpack the training batch from our dataloader. Copy each tensor to the GPU \n",
        "\n",
        "        # Each `batch` contains 4 tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: sentence ID\n",
        "        #   [3]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_sent_ids = batch[2].to(device)\n",
        "        b_labels = batch[3].to(device)\n",
        "\n",
        "        # Always reset the gradients before performing a backward pass \n",
        "        model.zero_grad()        \n",
        "\n",
        "        # Perform a forward pass (evaluate the BERT model on this training batch)\n",
        "        # If we provide the labels, this output will give us the loss of the batch\n",
        "        outputs = model(b_input_ids, \n",
        "                    token_type_ids=b_sent_ids, \n",
        "                    attention_mask=b_input_mask, \n",
        "                    labels=b_labels)\n",
        "        \n",
        "        # Take the first element of the tuple\n",
        "        loss = outputs[0]\n",
        "\n",
        "        # Accumulate the loss of this train batch to compute the average at the end\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0 to prevent \"exploding gradients\"\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient based on their Hyper-parameters (learn rate, gradients and so on)\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learn rate\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over this train set\n",
        "    avg_train_loss = total_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Store the loss value for future plots of the learning curve\n",
        "    loss_values.append(avg_train_loss)\n",
        "\n",
        "    print(\"\\n\\tAverage training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"\\tTraining epcoh time: {:}\".format(format_time(time.time() - t0)))\n",
        "        \n",
        "    # ============= Validation Phase =================\n",
        "\n",
        "    # Measure the performance on the validation set in every epoch\n",
        "\n",
        "    print(\"> Validation Mode...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Set the model in evaluation mode, because the dropout behaves differently during validation\n",
        "    model.eval()\n",
        "\n",
        "    # Track all the variables \n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "    ## Save the predictions   \n",
        "    vec_pred = np.array([])\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in dev_dataloader:\n",
        "      \n",
        "        # Unpack the development batch from our dataloader. Copy each tensor to the GPU\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_sent_ids = batch[2].to(device)\n",
        "        b_labels = batch[3].to(device)\n",
        "        \n",
        "        # Tell the model not to compute or store gradients\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            # Perform the forward pass. This output will return the predictions, because we haven't specified the labels\n",
        "            outputs = model(b_input_ids, \n",
        "                            token_type_ids=b_sent_ids, # Same as \"segment ids\", which differentiates sentence 1 and 2 \n",
        "                            attention_mask=b_input_mask)\n",
        "        \n",
        "        # Get the \"logits\" output, which are the predictions befroe applying the activation function (e.g., softmax)\n",
        "        logits = outputs[0]\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "        \n",
        "        ##\n",
        "        batch_pred = np.argmax(logits, axis=1).flatten() ## predictions of every batch\n",
        "        vec_pred = np.append(vec_pred, batch_pred) ## Save the batch predictions in the main vec_pred\n",
        "        \n",
        "        # Calculate the accuracy for this batch of test sentences\n",
        "        tmp_eval_accuracy = accuracy_score(label_ids.flatten(), np.argmax(logits, axis=1).flatten())\n",
        "        #tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "        \n",
        "        # Accumulate the total accuracy\n",
        "        eval_accuracy += tmp_eval_accuracy\n",
        "\n",
        "        # Track the number of batches\n",
        "        nb_eval_steps += 1\n",
        "\n",
        "    # Final accuracy for this validation epoch\n",
        "    print(\"\\tAccuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
        "    print(\"\\tValidation epoch time: {:}\".format(format_time(time.time() - t0)))\n",
        "\n",
        "print(\"\\nTraining complete!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "> Training Mode...\n",
            "\tBatch 40/352.\tElapsed: 0:00:39.\n",
            "\tBatch 80/352.\tElapsed: 0:01:18.\n",
            "\tBatch 120/352.\tElapsed: 0:01:56.\n",
            "\tBatch 160/352.\tElapsed: 0:02:35.\n",
            "\tBatch 200/352.\tElapsed: 0:03:14.\n",
            "\tBatch 240/352.\tElapsed: 0:03:53.\n",
            "\tBatch 280/352.\tElapsed: 0:04:32.\n",
            "\tBatch 320/352.\tElapsed: 0:05:11.\n",
            "\n",
            "\tAverage training loss: 0.74\n",
            "\tTraining epcoh time: 0:05:41\n",
            "> Validation Mode...\n",
            "\tAccuracy: 0.79\n",
            "\tValidation epoch time: 0:00:14\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "> Training Mode...\n",
            "\tBatch 40/352.\tElapsed: 0:00:39.\n",
            "\tBatch 80/352.\tElapsed: 0:01:18.\n",
            "\tBatch 120/352.\tElapsed: 0:01:56.\n",
            "\tBatch 160/352.\tElapsed: 0:02:35.\n",
            "\tBatch 200/352.\tElapsed: 0:03:14.\n",
            "\tBatch 240/352.\tElapsed: 0:03:53.\n",
            "\tBatch 280/352.\tElapsed: 0:04:32.\n",
            "\tBatch 320/352.\tElapsed: 0:05:11.\n",
            "\n",
            "\tAverage training loss: 0.46\n",
            "\tTraining epcoh time: 0:05:41\n",
            "> Validation Mode...\n",
            "\tAccuracy: 0.82\n",
            "\tValidation epoch time: 0:00:14\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "> Training Mode...\n",
            "\tBatch 40/352.\tElapsed: 0:00:39.\n",
            "\tBatch 80/352.\tElapsed: 0:01:18.\n",
            "\tBatch 120/352.\tElapsed: 0:01:57.\n",
            "\tBatch 160/352.\tElapsed: 0:02:36.\n",
            "\tBatch 200/352.\tElapsed: 0:03:14.\n",
            "\tBatch 240/352.\tElapsed: 0:03:53.\n",
            "\tBatch 280/352.\tElapsed: 0:04:32.\n",
            "\tBatch 320/352.\tElapsed: 0:05:11.\n",
            "\n",
            "\tAverage training loss: 0.32\n",
            "\tTraining epcoh time: 0:05:42\n",
            "> Validation Mode...\n",
            "\tAccuracy: 0.82\n",
            "\tValidation epoch time: 0:00:14\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "> Training Mode...\n",
            "\tBatch 40/352.\tElapsed: 0:00:39.\n",
            "\tBatch 80/352.\tElapsed: 0:01:18.\n",
            "\tBatch 120/352.\tElapsed: 0:01:57.\n",
            "\tBatch 160/352.\tElapsed: 0:02:35.\n",
            "\tBatch 200/352.\tElapsed: 0:03:14.\n",
            "\tBatch 240/352.\tElapsed: 0:03:53.\n",
            "\tBatch 280/352.\tElapsed: 0:04:32.\n",
            "\tBatch 320/352.\tElapsed: 0:05:11.\n",
            "\n",
            "\tAverage training loss: 0.24\n",
            "\tTraining epcoh time: 0:05:42\n",
            "> Validation Mode...\n",
            "\tAccuracy: 0.81\n",
            "\tValidation epoch time: 0:00:14\n",
            "\n",
            "Training complete!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UoDRi-GdnnsK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "4a421cde-4660-46c1-c96e-f380a472f617"
      },
      "source": [
        "# Plot the Loss value through the epochs\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "x = range(0,4)\n",
        "plt.plot(x, loss_values, '-')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Training Loss')\n",
        "plt.xticks([0,1,2,3])\n",
        "plt.title('Training loss over every epoch ')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXhV5dX38e/KDCTMIcwElCmIiCSgVqkVQbQK9bUqWmXSWq1Tq7XVvn36+Pi0r622Wm2tUwGx1qm2tbZWwYGhapUERSXM86CBMCcgCYH1/nF28BgJhJCTneT8Ptd1Lva8V84JWWffa9/3NndHRETiV0LYAYiISLiUCERE4pwSgYhInFMiEBGJc0oEIiJxTolARCTOKRHIEZnZK2Y2oa63PcoYzjSzDXV9XGm4zGy2mV0ddhzxICnsACQ2zKw0arY5UAbsD+a/4+5/qumx3P3cWGwrIg2DEkET5e7pldNmtga42t1fr7qdmSW5e0V9xiYRYb73+twlmpqG4kxlE4uZ/cjMioBpZtbGzP5pZsVmtj2Y7hq1z8FLdDObaGZvmdmvgm1Xm9m5tdy2p5nNNbMSM3vdzB4ys6dq+HP0D861w8wKzWxM1LrzzGxRcNyNZvaDYHn74GfbYWbbzOzfZnbI/wNmdpqZ5ZvZzuDf04Lll5pZQZVtv29mLwXTqcHPu87MNpnZI2bWrLr3vppzTzazxcF7NsPMegTLHzazX1XZ9u9mdksw3dnM/hJ8jqvN7Kao7e40sxfM7Ckz2wXcbmZ7zKxd1DYnB/smHyKmBDO73cxWmtlWM3vezNoG67LNzM3sGjP7xMw+rXzPo96T3wTrPgmmU6PWjzWzBWa2Kzj+6KhT9zCzt4PPcqaZtT/UeybHyN31auIvYA1wdjB9JlAB/BJIBZoB7YCLiDQhZQB/Bl6M2n82kSsKgInAPuDbQCJwHfAJYLXY9j/Ar4AU4HRgF/BUNT/DmcCGYDoZWAH8ONj3LKAE6Bus/xQ4I5huA5wcTN8NPBLsnwycURlLlXO1BbYDVxK5ar4smG8XvEclQO+o7fOBccH0/cBLwTEygH8Ad1f33h/i3GODn61/cO6fAO8E64YD66PevzbAZ0BnIl/q5gM/Dd6TXsAq4Jxg2zuDz+IbwbbNgH8B10Wd+37gt9W8/zcD7wJdg9gfBZ4J1mUDDjwDtAAGAsV8/jt3V7BvByATeAf432DdUGAnMDKIqwvQL+p3aSXQJ4h3NvCLsP8/NcVX6AHoVQ8f8pcTQTmQdpjtTwK2R83P5ot/3FdErWse/BHoeDTbAt2DP4rNo9Y/Rc0SwRlAEZAQtf4Z4M5geh3wHaBllWPcBfwdOP4I79eVwLwqy/4DTIyK86fBdG8iiaE5YMBu4Lio/U4FVh/Fe/8KcFXUfAKwB+gRHH8dMDxY923gzWB6GLCuyrHuAKYF03cCc6usvxR4O5hODN7TodXEtRgYETXfiUhiSeLzRNAvav09wJRgeiVwXtS6c4A1wfSjwP3VnHM28JOo+e8Cr4b9/6kpvtQ0FJ+K3X1v5YyZNTezR81sbdBsMBdobWaJ1exfVDnh7nuCyfSj3LYzsC1qGUS+7dZEZ2C9ux+IWraWyLdJiFzdnAesNbM5ZnZqsPxeIt+2Z5rZKjO7/TDHX1tlWfTxnyZylQBwOZGrpz1Evu02B+YHzU87gFeD5ZW+8N4fQg/ggaj9txFJAF088tfw2Srn/lPUfp0r9wv2/TGQFXXsqu/v34EcM+tJ5Bv5Tnefd5i4/hZ17MVEbj6o7vhribyP8OX3M3pdNyKJojpFUdN7qP73TI6BEkF8qjrk7K1AX2CYu7ck0gQBkT9AsfIp0NbMmkct61bDfT8BulVp3+8ObARw93x3H0ukKeJF4PlgeYm73+ruvYAxwC1mNqKa4/eosuzg8YHXgEwzO4nIH+Wng+VbiDTVDHD31sGrlUcV7vnye1/VeiJ3dbWOejVz93eC9c8A3wzqBsOAv0Ttt7rKfhnufl515w4S0vPAFUSugv54hLjOrXL8NHffGLVN9OfXncj7CF9+P6PXrQeOO8x5pR4oEQhE2rI/A3YEBcD/jvUJ3X0tUADcaWYpwbf2C2q4+3tEvh3+0MySzezMYN9ng2N9y8xaufs+InWHAwBmdr6ZHW9mRqRden/luir+BfQxs8vNLMnMLgVygH8Gse8jUke5l0gt4LVg+QHgceB+M+sQnLOLmZ1zFG/NI8AdZjYg2L+VmV1cudLdPyCScP4AzHD3HcGqeUBJUIhuZmaJZnaCmeUd4XxPEmnCG8PhE8EjwM+jCteZZja2yjb/FVxdDgAmAc8Fy58BfhLs055IHaPypoApwCQzGxEUpLuYWb8jxCx1TIlAAH5DpBi3hUhR79V6Ou+3iLShbwV+RuQPR9mRdnL3ciJ/+M8lEvPvgfHuviTY5EpgTdDMdW1wHoi0578OlBJp8/+9u886xPG3AucTuVLaCvwQON/dt0Rt9jRwNvBn/+JtmD8i0vz0bnD+14lcbdWIu/+NSDH52WD/hcHPGa3y3E9H7bc/iPkkYDWfJ4tWRzjf20SS4ftBcq7OA0SK4DPNrITI78mwKtvMIfKzvwH8yt1nBst/RiTpfwR8DLwfLCNoippEpFC9MzhG1asxibHKuw9EQmdmzwFL3D3mVyTyOTN7E3ja3f9Qy/2ziSSfZFffhEZJVwQSGjPLM7PjgiaB0URunXwx7LjiSdB0dDKfN+NIHFLPYglTR+CvRO7P30DknvYPwg0pfpjZdCL9Cm5295Kw45HwqGlIRCTOqWlIRCTONbqmofbt23t2dnbYYYiINCrz58/f4u6Zh1rX6BJBdnY2BQUFR95QREQOMrNqbw9W05CISJxTIhARiXNKBCIicU6JQEQkzikRiIjEOSUCEZE4p0QgIhLn4iYRrNmym1++ugQNqSEi8kVxkwhmLiri4dkr+cWrS468sYhIHGl0PYtr69tn9GL9ts94dM4qMtNTufqMXmGHJCLSIMRNIjAz7hwzgC2lZfzs5cW0T0/lG4O7HHlHEZEmLm6ahgASE4z7Lz2JYT3b8oM/f8jcZcVhhyQiErq4SgQAacmJPD4hl95ZGVz71Hw+XL/jyDuJiDRhcZcIAFqmJTN9Uh5tW6Qw6Yl8Vm/ZHXZIIiKhictEANChZRpPTh4KwPip77F5196QIxIRCUfcJgKAXpnpTJ2Yx9bSciZMy2fX3n1hhyQiUu/iOhEAnNStNQ9fMYTlm0q45skC9u7bH3ZIIiL1Ku4TAcBX+2Ry78Un8u6qbdzy/AL2H1DvYxGJH3HTj+BILhzclS0l5fz8X4tpn17I/4wZgJmFHZaISMwpEUT59vBeFJeW8djcSO/jG0f0DjskEZGYi2nTkJmNNrOlZrbCzG4/xPr7zWxB8FpmZqHf1H/76H5cOLgLv35tGc/OWxd2OCIiMRezKwIzSwQeAkYCG4B8M3vJ3RdVbuPu34/a/kZgcKziqamEBOOeb57Itt3l/PhvH9MuPZWROVlhhyUiEjOxvCIYCqxw91XuXg48C4w9zPaXAc/EMJ4aS05M4PffOpmBXVpxw9PvU7BmW9ghiYjETCwTQRdgfdT8hmDZl5hZD6An8GY1668xswIzKygurp/xgVqkJjF1Yh5dWjdj8hP5LNtUUi/nFRGpbw3l9tFxwAvufsib+N39MXfPdffczMzMeguqXXoq0ycPJS05kfFT5rFxx2f1dm4RkfoSy0SwEegWNd81WHYo42ggzUJVdWvbnOmTh7K7rIIJU+exfXd52CGJiNSpWCaCfKC3mfU0sxQif+xfqrqRmfUD2gD/iWEsx6R/p5Y8PiGXddv2MHl6Pp+Vq/exiDQdMUsE7l4B3ADMABYDz7t7oZndZWZjojYdBzzrDfxhwqf0ascDl57EgvU7uP7p99m3/0DYIYmI1Alr4H9/vyQ3N9cLCgpCO/9T767lJy8u5OIhXbnnmyeq97GINApmNt/dcw+1Tj2Lj9IVp/Rgc0kZD76xnMyMVH44ul/YIYmIHBMlglr4/tm9KS4p4/ezV5KZkcqkr/QMOyQRkVpTIqgFM+Nn3ziBraVl3PXPRbRPT+WCQZ3DDktEpFYaSj+CRicxwXjwssHk9WjLLc8v4K3lW8IOSUSkVpQIjkFaciKPT8ilV/t0vvPHAhZu3Bl2SCIiR02J4Bi1apbM9MlDad08hYnT5rF26+6wQxIROSpKBHWgY6s0pk8eyv4DzpVT5lFcUhZ2SCIiNaZEUEeO75DO1Il5FJeUMXHaPEr27gs7JBGRGlEiqEODu7fh91eczJKiEq59aj5lFRqKQkQaPiWCOva1vh2456ITeXvFVm59/kMOHGhcPbdFJP6oH0EMXDSkK8WlZfzilSW0T0/lvy/I0VAUItJgKRHEyHeG92LzrjKmvr2aDi1T+e6Zx4cdkojIISkRxIiZ8ZOv92dLaRn3vLqU9umpXJLb7cg7iojUMyWCGEpIMH518SC27ynnjr9+TLsWKYzonxV2WCIiX6BicYylJCXw8BVDyOnUkuuffp/5a7eHHZKIyBcoEdSD9NQkpk3Ko2PLNK6ans+KzSVhhyQicpASQT1pn57Kk5OHkZSQwPgp8/h052dhhyQiAigR1Kvu7ZrzxKQ8du2tYMLUeezco97HIhI+JYJ6dkKXVjx25RDWbNnDVdPz2btPvY9FJFxKBCE47fj23H/pScxft50bnv6Aiv0Hwg5JROKYEkFIvn5iJ+68YACvL97ET15ciLuGohCRcKgfQYgmnJZNcUkZv5u1gsyMVG4d1TfskEQkDikRhOzWUX0oLinjt29GksH4U7PDDklE4owSQcjMjJ9feAJbd5fz3y8V0q5FKl8/sVPYYYlIHFGNoAFISkzgt5cN5uTubfj+cwt4Z+WWsEMSkTiiRNBANEtJZMqEXHq0a841T86n8JOdYYckInFCiaABad08hemTh5KRlsTEafms37Yn7JBEJA4oETQwnVs348nJQymvOMCVU95jS2lZ2CGJSBOnRNAA9c7KYOrEXIp27WXyE/nsLqsIOyQRacKUCBqoIT3a8rvLTqbwk11c+9R8yivU+1hEYkOJoAE7OyeLu//PQP69fAu3vfAhBw6o97GI1L2YJgIzG21mS81shZndXs02l5jZIjMrNLOnYxlPY3RJbjduO6cvf1/wCT//12INRSEidS5mHcrMLBF4CBgJbADyzewld18UtU1v4A7gK+6+3cw6xCqexuy7Zx5HcUkZU95aTYeMVL7z1ePCDklEmpBY9iweCqxw91UAZvYsMBZYFLXNt4GH3H07gLtvjmE8jZaZ8dPzcyguLePuV5bQPj2Vi4Z0DTssEWkiYtk01AVYHzW/IVgWrQ/Qx8zeNrN3zWz0oQ5kZteYWYGZFRQXF8co3IYtIcG475JBfOX4dvzwLx8xa6lypojUjbCLxUlAb+BM4DLgcTNrXXUjd3/M3XPdPTczM7OeQ2w4UpMSeeSKIfTrmMF3n3qfD9ZtDzskEWkCYpkINgLdoua7BsuibQBecvd97r4aWEYkMUg1MtKSeWLSUDIzUpn8RD4ri0vDDklEGrlYJoJ8oLeZ9TSzFGAc8FKVbV4kcjWAmbUn0lS0KoYxNQmZGak8OXkoiQnG+CnzKNq5N+yQRKQRi1kicPcK4AZgBrAYeN7dC83sLjMbE2w2A9hqZouAWcBt7r41VjE1JdntWzBt4lB27ClnwtR57PxsX9ghiUgjZY3tvvTc3FwvKCgIO4wG463lW5j0xDwGd2/Dk5OHkpacGHZIItIAmdl8d8891Lqwi8VyjE7v3Z5fX3IS81Zv4+ZnP2C/eh+LyFFSImgCxgzqzE/Pz2FG4Sb+6+8L1ftYRI6KHlXZREw+vSfFpWU8PHslHTJS+d7ZfcIOSUQaCSWCJuSH5/SluKSM37y+nPbpqVxxSo+wQxKRRkCJoAkxM+7+PwPZtrucn/59Ie3TUxh9QqewwxKRBk41giYmOTGBhy4/mUHdWnPTswt4d5XuxhWRw1MiaIKapSQydUIe3do049tPFrD4011hhyQiDdhRJQIzSzCzlrEKRupOmxYpPHnVMFqkJDFh6jzWb9sTdkgi0kAdMRGY2dNm1tLMWgALgUVmdlvsQ5Nj1aV1M6ZPHsreffuZMHUe23aXhx2SiDRANbkiyHH3XcA3gFeAnsCVMY1K6kzfjhlMmZjHxh2fMemJfPaUV4Qdkog0MDVJBMlmlkwkEbzk7vsA9VhqRPKy2/Lbywbz8YYdXPfU++zbfyDskESkAalJIngUWAO0AOaaWQ9A1cdGZtSAjvz8woHMWVbMj174iAMaikJEAkfsR+DuDwIPRi1aa2Zfi11IEiuXDe1OcUkZ9722jMyMVO44r3/YIYlIA1CTYvHNQbHYzGyKmb0PnFUPsUkM3HjW8Vx5Sg8enbuKP/xbj34QkZo1DU0OisWjgDZECsW/iGlUEjNmxp1jBnDewI787OXFvPhB1YfGiUi8qUkisODf84A/unth1DJphBITjPsuOYlTerXlB3/+kLnLisMOSURCVJNEMN/MZhJJBDPMLAPQbSeNXFpyIo+Nz6V3VgbXPjWfD9fvCDskEQlJTRLBVcDtQJ677wFSgEkxjUrqRcu0ZKZPyqNtixQmPZHPquLSsEMSkRAcMRG4+wGgK/ATM/sVcJq7fxTzyKRedGiZxpOThwIwfuo8Nu/aG3JEIlLfanLX0C+Am4FFwesmM/t/sQ5M6k+vzHSmTcxj2+5yJkzLZ9fefWGHJCL1qCZNQ+cBI919qrtPBUYD58c2LKlvg7q15pErhrB8UwnXPFnA3n37ww5JROpJTUcfbR013SoWgUj4hvfJ5FcXD+LdVdu45fkF7FfvY5G4UJMnlN0NfGBms4jcNjqcSPFYmqBvDO7CltIyfvbyYtq1KOSusQMw093CIk1ZTYaYeMbMZgN5waIfAXoYbhN29Rm92FxSxmNzV9EhI5UbR/QOOyQRiaEaPbPY3T8FXqqcN7N5QPdYBSXhu310P7aUlPHrYFyicUP1cYs0VbV9eL3aCpq4hATjl988ka27y/nx3z6mbYsURg3oGHZYIhIDtX1msaqIcSA5MYHff+tkBnZtzY3PfED+mm1hhyQiMVDtFYGZ/YND/8E3oF3MIpIGpUVqEtMm5vHNh9/hqify+fO1p9G3Y0bYYYlIHTL3Q3+5N7OvHm5Hd58Tk4iOIDc31wsKCsI4dVxbv20PFz38Dglm/OW7p9GldbOwQxKRo2Bm890995DrqksEDZUSQXgWf7qLSx79Dx0yUnnh2tNo0yIl7JBEpIYOlwhqWyOQONS/U0seH5/L+u2fMXl6PnvKK8IOSUTqQEwTgZmNNrOlZrbCzL7UCc3MJppZsZktCF5XxzIeOXan9GrHg+NO4sP1O7jh6Q/Yt18jkos0djFLBGaWCDwEnAvkAJeZWc4hNn3O3U8KXn+IVTxSd0af0Im7xp7Am0s2c8dfP6axNS+KyBcdsR9BNXcP7QQKgEfdvbpxi4cCK9x9VXCcZ4GxREYwlUbuilN6UFxSxgNvLCczI5Ufje4XdkgiUks1uSJYBZQCjwevXUAJ0CeYr04XYH3U/IZgWVUXmdlHZvaCmXU71IHM7BozKzCzguJiPVaxofje2b25fFh3Hp69kqlvrQ47HBGppZr0LD7N3fOi5v9hZvnunmdmhcd4/n8Az7h7mZl9B5gOnFV1I3d/DHgMIncNHeM5pY6YGf879gS2lpZx1z8X0T4jlTGDOocdlogcpZpcEaSb2cGBZoLp9GC2/DD7bQSiv+F3DZYd5O5b3b0smP0DMKQG8UgDkphgPDBuMEN7tuXW5xfw1vItYYckIkepJongVuAtM5sVjEL6b+AHZtaCyDf46uQDvc2sp5mlAOOIGrgOwMw6Rc2OARYfTfDSMKQlJ/L4+FyOy0znO38sYOHGnWGHJCJHoSbPLP4X0Bv4HpFHVvZ195fdfbe7/+Yw+1UANwAziPyBf97dC83sLjMbE2x2k5kVmtmHwE3AxGP7cSQsrZolM33yUFo3T2HitHms3bo77JBEpIZq1LPYzE4DsomqKbj7k7ELq3rqWdywrdhcysWPvENGWjJ/ue40MjNSww5JRDjGnsVm9kfgV8DpRB5Okwcc8mAix3dIZ+rEPIpLypg4bR4le/eFHZKIHEFN7hrKBXJcvYakhgZ3b8PvrziZq6cXcO1T85k6MY/UpMSwwxKRatSkWLwQ0BNJ5Kh8rW8H7rnoRN5esZVbnv+QAwf0PUKkoarJFUF7YFHweMrKWz1x9zHV7yICFw3pypbSMu5+ZQmZ6an89wU5mOnhdiINTU0SwZ2xDkKarmuG92JzSRlT3lpNZkYq13/t+LBDEpEqjpgIwnoAjTQNZsb/Pa8/W0rLuHfGUjIzUrkk95AjiYhISA73qMq33P10Myvhi4POGeDu3jLm0UmTkJBg3PvNQWzbXc4df/2Ydi1SGNE/K+ywRCRQbbHY3U8P/s1w95ZRrwwlATlaKUkJPHzFEAZ0bsn1T7/P/LXbww5JRAI1eh6BmSWaWWcz6175inVg0vSkpyYxdWIeHVumMfmJfJZvKgk7JBGhZh3KbgQ2Aa8BLwevf8Y4Lmmi2qen8serhpGSlMD4qfP4dOdnYYckEvdqckVQOb7QAHcfGLxOjHVg0nR1a9ucJyblUbK3gvFT5rFt9+EGsRWRWKtJIlhP5IlkInVmQOdWPDZ+CGu37uHMe2fx+9kr+Kx8f9hhicSlIw46Z2ZTgL5EmoSiO5TdF9vQDk2DzjUtS4p2ce+rS3ljyWYyM1K5aURvxuV1IzkxZo/TFolLxzToHLCOSH0gBciIeokcs34dWzJlYh5/vvZUsts1579eXMjZ983h7ws2algKkXpSo2GoGxJdETRd7s7spcX88tUlLCkqoX+nltx2Th++1reDhqYQOUaHuyKoNhGY2W/c/Xtm9g++2KEMCG+sISWCpu/AAecfH33Cr2cuY922PeRlt+GHo/uRl9027NBEGq3aJoIh7j7fzL56qPVhDT2hRBA/yisO8FzBeh58YznFJWWc1a8Dt53Tl/6d1J9R5GjVKhE0VEoE8eez8v088c4aHp69gpKyCsYM6swtI/vQo12LsEMTaTSOKRGYWW/gbiAHSKtc7u696jLImlIiiF879+zjkbkrmfb2air2O+OGduOms3rToWXakXcWiXPHetfQNOBhoAL4GvAk8FTdhSdSM62aJ/Oj0f2Ye9vXGDe0G8/OW8/we2dxz6tL2PmZHokpUls1uSKY7+5DzOxjdx8YvaxeIqxCVwRSae3W3dz32jL+vuATWqYlcd2ZxzPxtGyapeixmCJVHesVQZmZJQDLzewGM7sQSK/TCEVqoUe7FjwwbjD/uukMcrPb8stXl/DVe2fx1Ltr2bf/QNjhiTQaNbkiyAMWA62B/wVaAve6+7uxD+/LdEUg1Zm3ehv3vLqEgrXb6dGuObeM7MMFJ3YmIUF9EERqXSw2s0Tgl+7+g1gFd7SUCORw3J1ZSzdzz6tLD3ZK++E5fTmzb6Y6pUlcq1XTkJkluft+4PSYRSZSx8yMs/pl8a+bzuCBcSexu6yCSU/kc+mj71KwZlvY4Yk0SIfrUPa+u59sZg8DXYA/A7sr17v7X+snxC/SFYEcjfKKAzyXv44H31xBcUkZI/p14AfqlCZxqLY9iysTwbSoxc7nzyyeXPehHpkSgdTGnvIKpr29hkfmrKS0rIKxgzpzy8i+dG/XPOzQROpFbRPBBuA+gj/8wb+VXMNQS2O0Y085j8xZxbS3V7P/gHPZ0O7cOOJ4OmSoU5o0bYdLBEmH2S+RyG2ih6qwNa5xKUQCrZuncPu5/Zj0lWwefGM5z8xbxwvzNzD59GyuGX4crZolhx2iSL07YtNQPcdzRLoikLq0ZkukU9pLH35Cq2bJXHfmcUw4VZ3SpOmpbYcy3WsnTV52+xY8eNlgXr7pdE7u3ppfvBLplPan99QpTeLH4RLBiGM9uJmNNrOlZrbCzG4/zHYXmZmb2SGzlUisDejcimmThvLcNafQrW1z/u/fFjLyvjm89OEnelKaNHnVJgJ3P6abroPOaA8B5xIZufQyM8s5xHYZwM3Ae8dyPpG6MKxXO1649lSmTMglLTmRm575gPN/+xazlm6msQ3ZLlJTsXxC+FBghbuvcvdy4Flg7CG2+1/gl8DeGMYiUmNmxoj+Wbx80xn85tKTKCnbx6Rp+Vz62LvMX6tOadL0xDIRdAHWR81vCJYdZGYnA93c/eUYxiFSK4kJxjcGd+GNW87krrEDWFW8m4se/g9XT89nSdGusMMTqTOxTASHFYxoeh9waw22vcbMCsysoLi4OPbBiURJSUpg/KnZzP3hmdx2Tl/eW72Ncx/4N99/bgHrtu4JOzyRYxazR1Wa2anAne5+TjB/B4C73x3MtwJWAqXBLh2BbcAYd6/2/lDdPiph27GnnIfnrOSJt9dwwJ3Lh3bnhrN6k5mRGnZoItUK5ZnFZpYELCNy99FGIB+43N0Lq9l+NvCDwyUBUCKQhqNo514efHM5z+WvJyUxgatO78m3h/dSpzRpkI71wTS14u4VwA3ADCLPM3je3QvN7C4zGxOr84rUl46t0vh/Fw7k9Vu+ytk5Wfxu1gqG3zOLR+esZO++/WGHJ1JjMbsiiBVdEUhDtXDjTu6dsZQ5y4rJapnKzSP6cHFuV5ITQyvFiRwUyhWBSLw5oUsrpk8eyrPXnEKX1s348d8+ZtT9c/mHOqVJA6dEIFLHTunVjr9cdxp/GJ9LSmICNz7zARf87i1mq1OaNFBKBCIxYGacnZPFv24+g/svHcTOz/YxcVo+4x57l/lrt4cdnsgXKBGIxFBignHh4K68eeuZ/M+YAaws3s1FD7/D1dMLWFpUEnZ4IoCKxSL1andZBdPeXs2jc1ZRWl7BhSd14fsj+9CtrZ6UJrEVSj+CWFEikKZg++5yHpmzkifeiXRK+9awHlz/tePVKU1iRolApIEq2rmXB95YzvMF60lN+rxTWss0dUqTuqVEINLArSou5b7XlvHPjz6ldfNkvnvmcYw/NZu0ZD0pTeqGEoFII7Fw407umbGUucuK6fyGhf8AAAvJSURBVNgyjZvP7s3FQ7qSpE5pcozUoUykkTihSyuenDyUZ759Cp1ap3HHXyOd0v75kTqlSewoEYg0QKce146/Xncaj4/PJSnRuOHpDxjz0FvMWVasTmlS55QIRBooM2NkThav3Dyc+y4ZxI49+5gwdR6XPf4u769TpzSpO6oRiDQSZRX7eea9dfxu1gq2lJYzMieL287pS5+sjLBDk0ZAxWKRJmR3WQVT31rNY3ODTmmDu/D9s9UpTQ5PiUCkCdq+O/KktOlRndJuOOt42qerU5p8mRKBSBP26c7PePCN5TxfsIHUpASuPr0nV6tTmlShRCASB1YVl/Lr15bxctAp7fozj+fKU3uoU5oASgQiceXjDTu5d+bnndK+d3ZvvqlOaXFPHcpE4sjArl/slHZ70Cnt5Y8+Vac0OSQlApEmqrJT2mNXDiExwbj+6fcZ+9DbzFWnNKlCiUCkCTMzRg3oyKvfG86vLx7Ett3ljJ86j8sff48P1ClNAqoRiMSRyk5pv31zBVt3lzMqJ4sfqFNaXFCxWES+oDSqU9qe8gouHNyV74/sTdc26pTWVCkRiMghbdtdzsOzVzD9P2vB4fJh3dUprYlSIhCRw/pkR2WntPWkJSdy5ak9uODEzgzo3BIzCzs8qQNKBCJSIyuLS7lv5jJeWfgpBxy6tG7GyJwsRuVkkdezLcnqi9BoKRGIyFHZUlrGm4s3M3NREXOXb6G84gCtmiUzon8HRuV0ZHif9jRPSQo7TDkKSgQiUmu7yyr49/JiZhZu4o0lm9n52T5SkxI4o3cmowZkMaJfB9qpptDgHS4RKKWLyGG1SE1i9AmdGH1CJ/btP0D+6m3MXLSJmYVFvL54EwkGudltGZWTxTkDOmo47EZIVwQiUivuTuEnu5hZWMTMRZtYUlQCQL+OGYwa0JFROVkqNjcgahoSkZhbu3U3ry3axMzCTeSv3YZHFZvPGdCRvOw2GvguRKElAjMbDTwAJAJ/cPdfVFl/LXA9sB8oBa5x90WHO6YSgUjDV1lsnlFYxL9XRIrNrZsnM6JfFqMGZDG8dybNUjQ8dn0KJRGYWSKwDBgJbADygcui/9CbWUt33xVMjwG+6+6jD3dcJQKRxmV3WQVzlxUzc9Em3li8iV17K0hLDorNOVmM6J9F2xYpYYfZ5IVVLB4KrHD3VUEQzwJjgYOJoDIJBFoAjaudSkSOqEVqEucO7MS5AyPF5nmrtx2sK7y2KFJszstue7CuoGJz/YvlFcE3gdHufnUwfyUwzN1vqLLd9cAtQApwlrsvP9xxdUUg0jS4Ows37mLmoiJmFm5i6aZIsbl/p5aMyok0IeV0UrG5roTVNFSjRBC1/eXAOe4+4RDrrgGuAejevfuQtWvXxiRmEQnPmi1BsXlREQVrtx8sNo8aECk25/ZQsflYhJUITgXudPdzgvk7ANz97mq2TwC2u3urwx1XVwQiTV9xSRlvLoncgVRZbG7TPJkR/SPDXZyhYvNRC6tGkA/0NrOewEZgHHB5lcB6RzUFfR04bLOQiMSHzIxULs3rzqV53Q8Wm2cUFjGjsIgX5m8gLTmB4b0zGTWgIyP6daCNis3HJGaJwN0rzOwGYAaR20enunuhmd0FFLj7S8ANZnY2sA/YDnypWUhE4lvVYvN7q7YdrCvMXLSJxAQjL7sNo3I6MlLF5lpRhzIRaZTcnY837gwSQhHLNpUCkNOpJaMGZDEqpyP9O2Wo2BxQz2IRafJWb9nNa8GVwvx1kWJzt7bNGJUTuS11SJwXm5UIRCSuFJeU8cbiSNPRW8u3UL7/AG1bpDCiXwdGDejIGb3bk5YcX8VmJQIRiVullT2bC4t4Y8lmSvZW0Cw5keF92jMqpyNnxUmxWcNQi0jcSk9N4ryBnThvYCfKKyI9m2cUFvHaok3MKIwUm4dmt2XUgCxG5mTRtU38FZt1RSAicenAgaDYHNQVlm+OFJsHdG4ZqSsMyKJfx6ZTbFbTkIjIEawqLg16Nm/i/aDY3L1t82C4i44M6dGGxITGmxSUCEREjsLmkr28sXgzMwuLeHvF1oPF5rODZzaf3giLzUoEIiK1VFpWwZylxcxcVMSbUcXmr/aJPLP5rH4daN284RebVSwWEaml9NQkvn5iJ75+YqTY/N7qrQc7sb1aWERigjGsZ+SZzSMHdKRL62Zhh3zUdEUgIlILlcXmGcGzFVYExeYTunxebO6b1XCKzWoaEhGJsZWVxebCIj5YvwN36NHu82Lzyd3DLTYrEYiI1KPNu/by+uLNzFxUxDtBsbldixTO7h954M5Xjq//YrMSgYhISEr27mPOsmJmFm5i1pLNlJRV0DwlqtjcN4tWzZNjHoeKxSIiIclIS+b8Eztz/omdKa84wLurth7sxPbKwiKSEoxhvdoeHEa7cwjFZl0RiIiE4MAB56ONO5lZpdg8sEsrRuVkcc4JHendIb3Ois1qGhIRaeAqi80zCov4YN0OALLbNWfUgMgw2oOPsdisRCAi0ohs3rWX1xZHntn8zsot7NvvtE9P4b/Oz2HsSV1qdUzVCEREGpEOLdP41rAefGtYD0r27mP20mJmLtpEp1axqR8oEYiINGAZaclcMKgzFwzqHLNzxO9z20REBFAiEBGJe0oEIiJxTolARCTOKRGIiMQ5JQIRkTinRCAiEueUCERE4lyjG2LCzIqBtbXcvT2wpQ7Dkbqhz6Xh0WfSMB3L59LD3TMPtaLRJYJjYWYF1Y21IeHR59Lw6DNpmGL1uahpSEQkzikRiIjEuXhLBI+FHYAckj6XhkefScMUk88lrmoEIiLyZfF2RSAiIlUoEYiIxLm4SQRmNtrMlprZCjO7Pex4BMxsqpltNrOFYcciEWbWzcxmmdkiMys0s5vDjinemVmamc0zsw+Dz+R/6vwc8VAjMLNEYBkwEtgA5AOXufuiUAOLc2Y2HCgFnnT3E8KOR8DMOgGd3P19M8sA5gPf0P+V8JiZAS3cvdTMkoG3gJvd/d26Oke8XBEMBVa4+yp3LweeBcaGHFPcc/e5wLaw45DPufun7v5+MF0CLAZq97R0qRMeURrMJgevOv0GHy+JoAuwPmp+A/rlFjksM8sGBgPvhRuJmFmimS0ANgOvuXudfibxkghE5CiYWTrwF+B77r4r7Hjinbvvd/eTgK7AUDOr06bUeEkEG4FuUfNdg2UiUkXQDv0X4E/u/tew45HPufsOYBYwui6PGy+JIB/obWY9zSwFGAe8FHJMIg1OUJicAix29/vCjkfAzDLNrHUw3YzITS9L6vIccZEI3L0CuAGYQaT49by7F4YblZjZM8B/gL5mtsHMrgo7JuErwJXAWWa2IHidF3ZQca4TMMvMPiLypfY1d/9nXZ4gLm4fFRGR6sXFFYGIiFRPiUBEJM4pEYiIxDklAhGROKdEICIS55QIRAJmtj/qlskFdTlKrZlla5RVaaiSwg5ApAH5LOjGLxJXdEUgcgRmtsbM7jGzj4Nx4Y8Plmeb2Ztm9pGZvWFm3YPlWWb2t2D8+A/N7LTgUIlm9ngwpvzMoJcoZnZTMP7/R2b2bEg/psQxJQKRzzWr0jR0adS6ne4+EPgd8Jtg2W+B6e5+IvAn4MFg+YPAHHcfBJwMVPZi7w085O4DgB3ARcHy24HBwXGujdUPJ1Id9SwWCZhZqbunH2L5GuAsd18VDMhW5O7tzGwLkYe47AuWf+ru7c2sGOjq7mVRx8gmMjRA72D+R0Cyu//MzF4l8oCeF4EXo8aeF6kXuiIQqRmvZvpolEVN7+fzGt3XgYeIXD3km5lqd1KvlAhEaubSqH//E0y/Q2QkW4BvAf8Opt8AroODDxRpVd1BzSwB6Obus4AfAa2AL12ViMSSvnmIfK5Z8BSoSq+6e+UtpG2C0R/LgMuCZTcC08zsNqAYmBQsvxl4LBhNdT+RpPBpNedMBJ4KkoUBDwZjzovUG9UIRI4gqBHkuvuWsGMRiQU1DYmIxDldEYiIxDldEYiIxDklAhGROKdEICIS55QIRETinBKBiEic+/9xF8HKofJBCgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xuzpe0-pNmY8",
        "colab_type": "text"
      },
      "source": [
        "### 5. TEST SET AND ERROR ANALYSIS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3CHsGxGDN2Uh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "37eb271c-9e8c-4b32-c7ea-c0ba913ae253"
      },
      "source": [
        "# Create a pandas dataframe\n",
        "test_df = pd.read_csv(\"./snli_1.0/snli_1.0_test.txt\", delimiter='\\t')\n",
        "test_df = test_df[['sentence1', 'sentence2', 'gold_label']]\n",
        "\n",
        "# Remove all the rows labeled as '-' and NaN\n",
        "test_df = test_df.loc[test_df['gold_label'] != '-']\n",
        "test_df = test_df.dropna()\n",
        "\n",
        "# Create a subset of the data\n",
        "test_df = test_df.iloc[:2500,:]\n",
        "\n",
        "# Check the length of the training set\n",
        "print('Length of the training set:', len(test_df))\n",
        "\n",
        "# Display the top 5 rows\n",
        "test_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of the training set: 2500\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence1</th>\n",
              "      <th>sentence2</th>\n",
              "      <th>gold_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>This church choir sings to the masses as they ...</td>\n",
              "      <td>The church has cracks in the ceiling.</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>This church choir sings to the masses as they ...</td>\n",
              "      <td>The church is filled with song.</td>\n",
              "      <td>entailment</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>This church choir sings to the masses as they ...</td>\n",
              "      <td>A choir singing at a baseball game.</td>\n",
              "      <td>contradiction</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A woman with a green headscarf, blue shirt and...</td>\n",
              "      <td>The woman is young.</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>A woman with a green headscarf, blue shirt and...</td>\n",
              "      <td>The woman is very happy.</td>\n",
              "      <td>entailment</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           sentence1  ...     gold_label\n",
              "0  This church choir sings to the masses as they ...  ...        neutral\n",
              "1  This church choir sings to the masses as they ...  ...     entailment\n",
              "2  This church choir sings to the masses as they ...  ...  contradiction\n",
              "3  A woman with a green headscarf, blue shirt and...  ...        neutral\n",
              "4  A woman with a green headscarf, blue shirt and...  ...     entailment\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SyrDM-pCOZB2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get the vector of sentences (A and B) and labels\n",
        "sentA = test_df.sentence1.values\n",
        "sentB = test_df.sentence2.values\n",
        "\n",
        "# Transform string labels into int labels\n",
        "labels = np.array([int_label[i] for i in test_df.gold_label])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKIZU58kOwNB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "05db81d5-4ec7-4a49-bd46-9e62cdd33922"
      },
      "source": [
        "# Shape of the sentences and labels\n",
        "print('Shape sentences A:', sentA.shape)\n",
        "print('Shape sentences B:', sentB.shape)\n",
        "print('Shape labels:', labels.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape sentences A: (2500,)\n",
            "Shape sentences B: (2500,)\n",
            "Shape labels: (2500,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QluAw8kkVpLz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# Tokenize all the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "sent_ids = []\n",
        "\n",
        "for i in range(0,2500):\n",
        "    # 'encode' will tokenize every word in the sentence, \n",
        "    # Add [CLS] and [SEP] special characters to the beggining and end of the sentence (also add [SEP] between sentA and B)\n",
        "    # Finally map every token to their ID\n",
        "    encoded_sent = tokenizer(\n",
        "                        sentA[i],\n",
        "                        sentB[i],                   \n",
        "                        add_special_tokens = True)\n",
        "    \n",
        "    sent_ids.append(encoded_sent['token_type_ids'])\n",
        "    input_ids.append(encoded_sent['input_ids'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bpNVdjtPZWGy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "04568d98-dbf9-4228-a23f-5d6932fd46e5"
      },
      "source": [
        "# Find the largest sentence in our IDs vector\n",
        "print('Length of the longest sentence:', max([len(sent) for sent in input_ids]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of the longest sentence: 76\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zggAJISHZK2P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "ca10196e-d0b1-4cc9-c40c-44e39c863232"
      },
      "source": [
        "# Set the maximum sequence length. It needs to be larger than 76\n",
        "max_len = 90\n",
        "\n",
        "print('Padding all the sentences to:',max_len)\n",
        "\n",
        "# Set PAD IDs as value=0 for the attention mask\n",
        "# \"post\" means that we add those special characters to the end of the sentence\n",
        "input_ids = pad_sequences(input_ids, maxlen=max_len, dtype=\"long\", \n",
        "                          value=0, truncating=\"post\", padding=\"post\")\n",
        "\n",
        "# SEt the PAD IDs as 1, as we move them to the back of the sentence\n",
        "sent_ids = pad_sequences(sent_ids, maxlen=max_len, dtype=\"long\", \n",
        "                          value=1, truncating=\"post\", padding=\"post\")\n",
        "\n",
        "print('Padding completed!')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Padding all the sentences to: 90\n",
            "Padding completed!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Y9VKMbPZ-RB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create attention mask vector\n",
        "att_masks = []\n",
        "\n",
        "for sent in input_ids:\n",
        "   \n",
        "    # This vector will have two possible values [0,1]. All the padding tokens can't be masked, so we need to set them as 0, the rest as 1\n",
        "    mask = [int(id > 0) for id in sent]\n",
        "    att_masks.append(mask)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wTum6FEaGyG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Transform the inputs, labels, attention masks and sentence IDs vectors into torch tensors\n",
        "X_test = torch.tensor(input_ids)\n",
        "y_test = torch.tensor(labels)\n",
        "masks_test = torch.tensor(att_masks)\n",
        "sentID_test = torch.tensor(sent_ids)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rsk7rXz8ZOnP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set the batch size, same size as in the training\n",
        "batch_size = 32  \n",
        "\n",
        "# DataLoader\n",
        "test_data = TensorDataset(X_test, masks_test, sentID_test, y_test)\n",
        "test_sampler = SequentialSampler(test_data)\n",
        "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7mTleQ6gnbLu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "e2ef3726-1329-42b3-d6f8-e26c00aea27a"
      },
      "source": [
        "print(\"Test Mode...\")\n",
        "\n",
        "t0 = time.time()\n",
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Store variables \n",
        "predictions , true_labels = [], []\n",
        "\n",
        "# ===== Test Phase ======= \n",
        "for batch in test_dataloader:\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  \n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids = batch[0].to(device)\n",
        "  b_input_mask = batch[1].to(device)\n",
        "  b_sent_ids = batch[2].to(device)\n",
        "  b_labels = batch[3].to(device)\n",
        "  \n",
        "  # Telling the model not to compute or store gradients, saving memory and \n",
        "  # speeding up prediction\n",
        "  with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions\n",
        "      outputs = model(b_input_ids, \n",
        "                      token_type_ids=b_sent_ids, \n",
        "                      attention_mask=b_input_mask)\n",
        "\n",
        "  logits = outputs[0]\n",
        "\n",
        "  # Move logits and labels to CPU\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "  \n",
        "  # Store predictions and true labels\n",
        "  predictions.append(logits)\n",
        "  true_labels.extend(label_ids)\n",
        "\n",
        "print(\"\\nEpoch time: {:}\".format(format_time(time.time() - t0)))\n",
        "print('\\nTest Phase Completed!')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Mode...\n",
            "\n",
            "Epoch time: 0:00:25\n",
            "\n",
            "Test Phase Completed!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYVQUxRdkTi_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "28145f75-5ccd-4529-eaae-222f2bb5cbd4"
      },
      "source": [
        "final_pred = np.array([])\n",
        "\n",
        "# For each input batch...\n",
        "for i in range(79):\n",
        "  pred_labels_i = np.argmax(predictions[i], axis=1).flatten()\n",
        "  final_pred = np.append(final_pred, pred_labels_i)\n",
        "\n",
        "print('Test Accuracy:', accuracy_score(true_labels, final_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy: 0.8272\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hqLzqTBAkVQA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Dictionary int2string labels\n",
        "str_labels = {0:'entailment', 1:'neutral', 2:'contradiction'}\n",
        "pred_label = [str_labels[i] for i in final_pred]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ASet8IXxyt0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "outputId": "f6adfb97-c1f6-487c-8341-5a42af7fbc5c"
      },
      "source": [
        "# Final Test data frame\n",
        "test_df['predictions'] = pred_label\n",
        "test_df.head(12)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence1</th>\n",
              "      <th>sentence2</th>\n",
              "      <th>gold_label</th>\n",
              "      <th>predictions</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>This church choir sings to the masses as they ...</td>\n",
              "      <td>The church has cracks in the ceiling.</td>\n",
              "      <td>neutral</td>\n",
              "      <td>contradiction</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>This church choir sings to the masses as they ...</td>\n",
              "      <td>The church is filled with song.</td>\n",
              "      <td>entailment</td>\n",
              "      <td>entailment</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>This church choir sings to the masses as they ...</td>\n",
              "      <td>A choir singing at a baseball game.</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>contradiction</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A woman with a green headscarf, blue shirt and...</td>\n",
              "      <td>The woman is young.</td>\n",
              "      <td>neutral</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>A woman with a green headscarf, blue shirt and...</td>\n",
              "      <td>The woman is very happy.</td>\n",
              "      <td>entailment</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>A woman with a green headscarf, blue shirt and...</td>\n",
              "      <td>The woman has been shot.</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>contradiction</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>An old man with a package poses in front of an...</td>\n",
              "      <td>A man poses in front of an ad.</td>\n",
              "      <td>entailment</td>\n",
              "      <td>entailment</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>An old man with a package poses in front of an...</td>\n",
              "      <td>A man poses in front of an ad for beer.</td>\n",
              "      <td>neutral</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>An old man with a package poses in front of an...</td>\n",
              "      <td>A man walks by an ad.</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>entailment</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>A statue at a museum that no seems to be looki...</td>\n",
              "      <td>The statue is offensive and people are mad tha...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>A statue at a museum that no seems to be looki...</td>\n",
              "      <td>There is a statue that not many people seem to...</td>\n",
              "      <td>entailment</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>A statue at a museum that no seems to be looki...</td>\n",
              "      <td>Tons of people are gathered around the statue.</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>contradiction</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            sentence1  ...    predictions\n",
              "0   This church choir sings to the masses as they ...  ...  contradiction\n",
              "1   This church choir sings to the masses as they ...  ...     entailment\n",
              "2   This church choir sings to the masses as they ...  ...  contradiction\n",
              "3   A woman with a green headscarf, blue shirt and...  ...        neutral\n",
              "4   A woman with a green headscarf, blue shirt and...  ...        neutral\n",
              "5   A woman with a green headscarf, blue shirt and...  ...  contradiction\n",
              "6   An old man with a package poses in front of an...  ...     entailment\n",
              "7   An old man with a package poses in front of an...  ...        neutral\n",
              "8   An old man with a package poses in front of an...  ...     entailment\n",
              "9   A statue at a museum that no seems to be looki...  ...        neutral\n",
              "10  A statue at a museum that no seems to be looki...  ...        neutral\n",
              "11  A statue at a museum that no seems to be looki...  ...  contradiction\n",
              "\n",
              "[12 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WhVbFRjzSFD3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "29a4a3b4-a126-430b-e06f-ea27c6efcda6"
      },
      "source": [
        "# Confusion Matrix\n",
        "from sklearn import metrics\n",
        "\n",
        "print('Confusion Matrix:')\n",
        "metrics.confusion_matrix(test_df.gold_label, test_df.predictions) # Rows = true labels and Col = predictions"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion Matrix:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[668,  43, 105],\n",
              "       [ 29, 753,  72],\n",
              "       [ 91,  92, 647]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idCL26PHwsBh",
        "colab_type": "text"
      },
      "source": [
        "__Comments:__ As we can see from the final results, BERT performs really well on the test set, reaching an accuracy of 82%. The final dataframe compares the true labels and the predictions with every pair of sentence and it looks like for a given sentence A (or 1), the model guesses 2/3 of the labels correct. \n",
        "\n",
        "The final confusion matrix gives us good insights of how well BERT is performing for each label. It looks like the one that has more good predictions is with neutral sentences. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j3sgYOnOlxkW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "34cab19a-241d-4a70-eb9f-1aeddf4cbe00"
      },
      "source": [
        "# Plot to compare Tf-idf, glove and BERT\n",
        "performance = [0.5956, 0.6272, 0.8212]\n",
        "models = ['tfidf', 'glove', 'BERT']\n",
        "\n",
        "plt.barh(models, performance, color=['green', 'red', 'blue'], alpha=0.6)\n",
        "plt.xlim([0.3,0.9])\n",
        "plt.xlabel('Test Accuracy')\n",
        "plt.title('Final Performance')\n",
        "plt.savefig('allmodels.png')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I1AlBZ1_7U5i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}